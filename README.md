**ğŸ™ï¸ Multi-User Voice-Enabled RAG Chatbot**

Speech-to-Text â†’ Retrieval-Augmented Generation â†’ Text-to-Speech
Supports PDFs, text files & voice ingestion â€¢ Personalized namespaces â€¢ Pinecone vector storage â€¢ Ollama LLM backend


**ğŸ“Œ Overview**

This project is a multi-user Retrieval-Augmented Generation (RAG) chatbot that supports:

âœ… Voice input (STT) using Whisper + sounddevice
âœ… Document ingestion (PDF, TXT, voice transcripts)
âœ… Vector storage per-user using Pinecone namespaces
âœ… Context-aware chat using LangChain Conversational Memory
âœ… LLM answering using Ollama (Mistral / Llama3 / etc.)
âœ… Voice output (TTS) for bot responses
âœ… Supports multiple users simultaneously

**The workflow:**

User â†’ (Speak) â†’ Whisper STT â†’ Query Vectorstore â†’ Ollama LLM â†’ TTS â†’ Bot Speaks Response


You can ingest files or voice notes into a userâ€™s private vector namespace, then ask questions verbally or textually.

**âœ¨ Features**

Feature	Description

ğŸ¤ STT Input	Whisper transcribes voice recordings (sounddevice)
ğŸ“„ Document ingestion	PDFs/TXT split into chunks and stored in Pinecone
ğŸ” RAG retrieval	LangChain + Pinecone vector search
ğŸ§  Per-User Memory	Each user has their own conversation buffer + namespace
ğŸ—‚ï¸ Pinecone VectorDB	Stores embeddings for all users separately
ğŸ¤– LLM Responses	Powered by Ollama + LangChain
ğŸ”Š TTS	Bot responses are spoken
ğŸ‘¥ Multi-User Support	user_id creates isolated namespaces


**ğŸ—ï¸ Project Architecture**


                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚     User (Voice)     â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ speak
                                      â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚     Whisper STT (local)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ text
                                      â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚      ConversationalRetrievalChain   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ retrieves
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Pinecone Vectorsâ”‚â—„â”€â”€ Ingest PDFs / Voice
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ context
                                â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚       Ollama LLM (Mistral etc.)     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ answer
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚         TTS Output       â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
